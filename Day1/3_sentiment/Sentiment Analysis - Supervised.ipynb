{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oklawyer71/ML1010_ClassExercies/blob/master/Day1/3_sentiment/Sentiment%20Analysis%20-%20Supervised.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6DUR_KE20NJ"
      },
      "source": [
        "# Import necessary depencencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "pHhvPrs020NK"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "#import text_normalizer as tn\n",
        "import model_evaluation_utils as meu\n",
        "\n",
        "np.set_printoptions(precision=2, linewidth=80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOBbpTit20NL"
      },
      "source": [
        "# Load and normalize data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Y_auOUTc20NL",
        "outputId": "ea00f7e1-8cb7-48c8-f670-24b74eee3908",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                              review sentiment\n",
            "0  not bother think would see movie great supspen...  negative\n",
            "1  careful one get mitt change way look kung fu f...  positive\n",
            "2  chili palmer tired movie know want success mus...  negative\n",
            "3  follow little know 1998 british film make budg...  positive\n",
            "4  dark angel cross huxley brave new world percys...  positive\n"
          ]
        }
      ],
      "source": [
        "dataset = pd.read_csv(r'movie_reviews_cleaned.csv')\n",
        "\n",
        "# take a peek at the data\n",
        "print(dataset.head())\n",
        "reviews = np.array(dataset['review'])\n",
        "sentiments = np.array(dataset['sentiment'])\n",
        "\n",
        "# build train and test datasets\n",
        "#train_reviews = reviews[:35000]\n",
        "#train_sentiments = sentiments[:35000]\n",
        "#test_reviews = reviews[35000:]\n",
        "#test_sentiments = sentiments[35000:]\n",
        "\n",
        "train_reviews = reviews[:5000]\n",
        "train_sentiments = sentiments[:5000]\n",
        "test_reviews = reviews[5000:7000]\n",
        "test_sentiments = sentiments[5000:7000]\n",
        "\n",
        "# normalize datasets\n",
        "#norm_train_reviews = tn.normalize_corpus(train_reviews)\n",
        "#norm_test_reviews = tn.normalize_corpus(test_reviews)\n",
        "\n",
        "norm_train_reviews = train_reviews\n",
        "norm_test_reviews = test_reviews\n",
        "\n",
        "# print some sample normalized reviews"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzRzpUcM20NL"
      },
      "source": [
        "# Traditional Supervised Machine Learning Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KyCj_aJm20NL"
      },
      "source": [
        "## Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "collapsed": true,
        "id": "mTSXjsH920NL"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "\n",
        "# build BOW features on train reviews\n",
        "cv = CountVectorizer(binary=False, min_df=0.0, max_df=1.0, ngram_range=(1,2))\n",
        "cv_train_features = cv.fit_transform(norm_train_reviews)\n",
        "# build TFIDF features on train reviews\n",
        "tv = TfidfVectorizer(use_idf=True, min_df=0.0, max_df=1.0, ngram_range=(1,2),\n",
        "                     sublinear_tf=True)\n",
        "tv_train_features = tv.fit_transform(norm_train_reviews)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "collapsed": true,
        "id": "8VtftF5m20NM"
      },
      "outputs": [],
      "source": [
        "# transform test reviews into features\n",
        "cv_test_features = cv.transform(norm_test_reviews)\n",
        "tv_test_features = tv.transform(norm_test_reviews)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "kYlZeqrF20NM",
        "outputId": "69d6691a-3c79-44fc-a4f0-d1a0ca03fe59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BOW model:> Train features shape: (5000, 434563)  Test features shape: (2000, 434563)\n",
            "TFIDF model:> Train features shape: (5000, 434563)  Test features shape: (2000, 434563)\n"
          ]
        }
      ],
      "source": [
        "print('BOW model:> Train features shape:', cv_train_features.shape, ' Test features shape:', cv_test_features.shape)\n",
        "print('TFIDF model:> Train features shape:', tv_train_features.shape, ' Test features shape:', tv_test_features.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2zh-sYq20NN"
      },
      "source": [
        "## Model Training, Prediction and Performance Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "collapsed": true,
        "id": "LjuPp2Qc20NN"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
        "\n",
        "lr = LogisticRegression(penalty='l2', max_iter=100, C=1)\n",
        "#svm = SGDClassifier(loss='hinge')\n",
        "\n",
        "svm = SGDClassifier(loss='hinge' , max_iter=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "xHlMf3R720NN",
        "outputId": "fbed9a3d-81ed-44be-9526-661655ed6bb4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Performance metrics:\n",
            "------------------------------\n",
            "Accuracy: 0.8605\n",
            "Precision: 0.8606\n",
            "Recall: 0.8605\n",
            "F1 Score: 0.8605\n",
            "\n",
            "Model Classification report:\n",
            "------------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    positive       0.85      0.86      0.86       981\n",
            "    negative       0.87      0.86      0.86      1019\n",
            "\n",
            "    accuracy                           0.86      2000\n",
            "   macro avg       0.86      0.86      0.86      2000\n",
            "weighted avg       0.86      0.86      0.86      2000\n",
            "\n",
            "\n",
            "Prediction Confusion Matrix:\n",
            "------------------------------\n",
            "                 Predicted:         \n",
            "                   positive negative\n",
            "Actual: positive        846      135\n",
            "        negative        144      875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "# Logistic Regression model on BOW features\n",
        "lr_bow_predictions = meu.train_predict_model(classifier=lr,\n",
        "                                             train_features=cv_train_features, train_labels=train_sentiments,\n",
        "                                             test_features=cv_test_features, test_labels=test_sentiments)\n",
        "meu.display_model_performance_metrics(true_labels=test_sentiments, predicted_labels=lr_bow_predictions,\n",
        "                                      classes=['positive', 'negative'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "scrolled": true,
        "id": "AtUloa4i20NO",
        "outputId": "70353aaa-be9a-4da1-dc19-8a29c63967a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Performance metrics:\n",
            "------------------------------\n",
            "Accuracy: 0.866\n",
            "Precision: 0.8661\n",
            "Recall: 0.866\n",
            "F1 Score: 0.866\n",
            "\n",
            "Model Classification report:\n",
            "------------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    positive       0.87      0.85      0.86       981\n",
            "    negative       0.86      0.88      0.87      1019\n",
            "\n",
            "    accuracy                           0.87      2000\n",
            "   macro avg       0.87      0.87      0.87      2000\n",
            "weighted avg       0.87      0.87      0.87      2000\n",
            "\n",
            "\n",
            "Prediction Confusion Matrix:\n",
            "------------------------------\n",
            "                 Predicted:         \n",
            "                   positive negative\n",
            "Actual: positive        838      143\n",
            "        negative        125      894\n"
          ]
        }
      ],
      "source": [
        "# Logistic Regression model on TF-IDF features\n",
        "lr_tfidf_predictions = meu.train_predict_model(classifier=lr,\n",
        "                                               train_features=tv_train_features, train_labels=train_sentiments,\n",
        "                                               test_features=tv_test_features, test_labels=test_sentiments)\n",
        "meu.display_model_performance_metrics(true_labels=test_sentiments, predicted_labels=lr_tfidf_predictions,\n",
        "                                      classes=['positive', 'negative'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "9lkcmB5I20NO",
        "outputId": "3be197b8-2065-4f1e-b62c-2d4c593f2bf3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Performance metrics:\n",
            "------------------------------\n",
            "Accuracy: 0.844\n",
            "Precision: 0.8441\n",
            "Recall: 0.844\n",
            "F1 Score: 0.844\n",
            "\n",
            "Model Classification report:\n",
            "------------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    positive       0.85      0.83      0.84       981\n",
            "    negative       0.84      0.86      0.85      1019\n",
            "\n",
            "    accuracy                           0.84      2000\n",
            "   macro avg       0.84      0.84      0.84      2000\n",
            "weighted avg       0.84      0.84      0.84      2000\n",
            "\n",
            "\n",
            "Prediction Confusion Matrix:\n",
            "------------------------------\n",
            "                 Predicted:         \n",
            "                   positive negative\n",
            "Actual: positive        816      165\n",
            "        negative        147      872\n"
          ]
        }
      ],
      "source": [
        "svm_bow_predictions = meu.train_predict_model(classifier=svm,\n",
        "                                             train_features=cv_train_features, train_labels=train_sentiments,\n",
        "                                             test_features=cv_test_features, test_labels=test_sentiments)\n",
        "meu.display_model_performance_metrics(true_labels=test_sentiments, predicted_labels=svm_bow_predictions,\n",
        "                                      classes=['positive', 'negative'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "p_7o34TK20NO",
        "outputId": "5c52d358-89b0-4389-ec42-fb88669c218a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Performance metrics:\n",
            "------------------------------\n",
            "Accuracy: 0.8795\n",
            "Precision: 0.8796\n",
            "Recall: 0.8795\n",
            "F1 Score: 0.8795\n",
            "\n",
            "Model Classification report:\n",
            "------------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    positive       0.88      0.87      0.88       981\n",
            "    negative       0.88      0.89      0.88      1019\n",
            "\n",
            "    accuracy                           0.88      2000\n",
            "   macro avg       0.88      0.88      0.88      2000\n",
            "weighted avg       0.88      0.88      0.88      2000\n",
            "\n",
            "\n",
            "Prediction Confusion Matrix:\n",
            "------------------------------\n",
            "                 Predicted:         \n",
            "                   positive negative\n",
            "Actual: positive        853      128\n",
            "        negative        113      906\n"
          ]
        }
      ],
      "source": [
        "svm_tfidf_predictions = meu.train_predict_model(classifier=svm,\n",
        "                                                train_features=tv_train_features, train_labels=train_sentiments,\n",
        "                                                test_features=tv_test_features, test_labels=test_sentiments)\n",
        "meu.display_model_performance_metrics(true_labels=test_sentiments, predicted_labels=svm_tfidf_predictions,\n",
        "                                      classes=['positive', 'negative'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5sw71FC20NO"
      },
      "source": [
        "# Newer Supervised Deep Learning Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "0FoiDWET20NO",
        "outputId": "6d7375b0-9306-4d34-9781-c5026a8abb54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-5e97895498ef>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mActivation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvis_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'vis_utils' from 'keras.utils' (/usr/local/lib/python3.10/dist-packages/keras/utils/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import gensim\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dropout, Activation, Dense\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "\n",
        "# Add the following\n",
        "\n",
        "import spacy\n",
        "import nltk\n",
        "from nltk.tokenize.toktok import ToktokTokenizer\n",
        "\n",
        "tokenizer = ToktokTokenizer()\n",
        "!python -m spacy download en_core_web_sm\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8LRIdM920NO"
      },
      "source": [
        "## Prediction class label encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Bq3171rx20NO"
      },
      "outputs": [],
      "source": [
        "le = LabelEncoder()\n",
        "num_classes=2\n",
        "# tokenize train reviews & encode train labels\n",
        "tokenized_train = [tokenizer.tokenize(text)\n",
        "                   for text in norm_train_reviews]\n",
        "y_tr = le.fit_transform(train_sentiments)\n",
        "y_train = keras.utils.to_categorical(y_tr, num_classes)\n",
        "# tokenize test reviews & encode test labels\n",
        "tokenized_test = [tokenizer.tokenize(text)\n",
        "                   for text in norm_test_reviews]\n",
        "y_ts = le.fit_transform(test_sentiments)\n",
        "y_test = keras.utils.to_categorical(y_ts, num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "rJKCiAqT20NO",
        "outputId": "f2f7a769-fb03-4817-fa70-dc85cae01064",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment class label map: {'negative': 0, 'positive': 1}\n",
            "Sample test label transformation:\n",
            "----------------------------------- \n",
            "Actual Labels: ['negative' 'negative' 'negative'] \n",
            "Encoded Labels: [0 0 0] \n",
            "One hot encoded Labels:\n",
            " [[1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]]\n"
          ]
        }
      ],
      "source": [
        "# print class label encoding map and encoded labels\n",
        "print('Sentiment class label map:', dict(zip(le.classes_, le.transform(le.classes_))))\n",
        "print('Sample test label transformation:\\n'+'-'*35,\n",
        "      '\\nActual Labels:', test_sentiments[:3], '\\nEncoded Labels:', y_ts[:3],\n",
        "      '\\nOne hot encoded Labels:\\n', y_test[:3])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wqyi-Qf20NO"
      },
      "source": [
        "## Feature Engineering with word embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "CdG_o1Oj20NO"
      },
      "outputs": [],
      "source": [
        "# build word2vec model\n",
        "w2v_num_features = 500\n",
        "w2v_model = gensim.models.Word2Vec(tokenized_train, vector_size=w2v_num_features, window=150,\n",
        "                                   min_count=10, sample=1e-3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "collapsed": true,
        "id": "TtprtMfy20NO"
      },
      "outputs": [],
      "source": [
        "#change index2word to index_to_key\n",
        "# Change model[word] to model.wv[word]\n",
        "\n",
        "def averaged_word2vec_vectorizer(corpus, model, num_features):\n",
        "  #vocabulary = set(model.wv.index2word)\n",
        "    vocabulary = set(model.wv.index_to_key)\n",
        "\n",
        "    def average_word_vectors(words, model, vocabulary, num_features):\n",
        "        feature_vector = np.zeros((num_features,), dtype=\"float64\")\n",
        "        nwords = 0.\n",
        "\n",
        "        for word in words:\n",
        "            if word in vocabulary:\n",
        "                nwords = nwords + 1.\n",
        "                feature_vector = np.add(feature_vector, model.wv[word])\n",
        "        if nwords:\n",
        "            feature_vector = np.divide(feature_vector, nwords)\n",
        "\n",
        "        return feature_vector\n",
        "\n",
        "    features = [average_word_vectors(tokenized_sentence, model, vocabulary, num_features)\n",
        "                    for tokenized_sentence in corpus]\n",
        "    return np.array(features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "collapsed": true,
        "id": "cPWvtC6z20NO"
      },
      "outputs": [],
      "source": [
        "# generate averaged word vector features from word2vec model\n",
        "avg_wv_train_features = averaged_word2vec_vectorizer(corpus=tokenized_train, model=w2v_model,\n",
        "                                                     num_features=500)\n",
        "avg_wv_test_features = averaged_word2vec_vectorizer(corpus=tokenized_test, model=w2v_model,\n",
        "                                                    num_features=500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "collapsed": true,
        "id": "UBOznK_u20NO"
      },
      "outputs": [],
      "source": [
        "# feature engineering with GloVe model\n",
        "train_nlp = [nlp(item) for item in norm_train_reviews]\n",
        "train_glove_features = np.array([item.vector for item in train_nlp])\n",
        "\n",
        "test_nlp = [nlp(item) for item in norm_test_reviews]\n",
        "test_glove_features = np.array([item.vector for item in test_nlp])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "T1mhjlYV20NO",
        "outputId": "14cfd92d-af45-4af7-82ee-b010a9324ae0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word2Vec model:> Train features shape: (5000, 500)  Test features shape: (2000, 500)\n",
            "GloVe model:> Train features shape: (5000, 96)  Test features shape: (2000, 96)\n"
          ]
        }
      ],
      "source": [
        "print('Word2Vec model:> Train features shape:', avg_wv_train_features.shape, ' Test features shape:', avg_wv_test_features.shape)\n",
        "print('GloVe model:> Train features shape:', train_glove_features.shape, ' Test features shape:', test_glove_features.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhbVVRPs20NP"
      },
      "source": [
        "## Modeling with deep neural networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyuytA5_20NP"
      },
      "source": [
        "### Building Deep neural network architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "CgGKVfHv20NP"
      },
      "outputs": [],
      "source": [
        "def construct_deepnn_architecture(num_input_features):\n",
        "    dnn_model = Sequential()\n",
        "    dnn_model.add(Dense(512, activation='relu', input_shape=(num_input_features,)))\n",
        "    dnn_model.add(Dropout(0.2))\n",
        "    dnn_model.add(Dense(512, activation='relu'))\n",
        "    dnn_model.add(Dropout(0.2))\n",
        "    dnn_model.add(Dense(512, activation='relu'))\n",
        "    dnn_model.add(Dropout(0.2))\n",
        "    dnn_model.add(Dense(2))\n",
        "    dnn_model.add(Activation('softmax'))\n",
        "\n",
        "    dnn_model.compile(loss='categorical_crossentropy', optimizer='adam',\n",
        "                      metrics=['accuracy'])\n",
        "    return dnn_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "collapsed": true,
        "id": "ovWWD3p920NP"
      },
      "outputs": [],
      "source": [
        "w2v_dnn = construct_deepnn_architecture(num_input_features=500)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2VqijDz20NP"
      },
      "source": [
        "### Visualize sample deep architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "nEarIQ2k20NP",
        "outputId": "6f394dd8-0d6d-42f6-a55b-981cf89ab321",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"309pt\" height=\"959pt\" viewBox=\"0.00 0.00 232.00 719.00\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(0.75 0.75) rotate(0) translate(4 715)\">\n<title>G</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-715 228,-715 228,4 -4,4\"/>\n<!-- 139924285273904 -->\n<g id=\"node1\" class=\"node\">\n<title>139924285273904</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"0,-664.5 0,-710.5 224,-710.5 224,-664.5 0,-664.5\"/>\n<text text-anchor=\"middle\" x=\"38.5\" y=\"-683.8\" font-family=\"Times,serif\" font-size=\"14.00\">InputLayer</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"77,-664.5 77,-710.5 \"/>\n<text text-anchor=\"middle\" x=\"104.5\" y=\"-695.3\" font-family=\"Times,serif\" font-size=\"14.00\">input:</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"77,-687.5 132,-687.5 \"/>\n<text text-anchor=\"middle\" x=\"104.5\" y=\"-672.3\" font-family=\"Times,serif\" font-size=\"14.00\">output:</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"132,-664.5 132,-710.5 \"/>\n<text text-anchor=\"middle\" x=\"178\" y=\"-695.3\" font-family=\"Times,serif\" font-size=\"14.00\">[(None, 500)]</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"132,-687.5 224,-687.5 \"/>\n<text text-anchor=\"middle\" x=\"178\" y=\"-672.3\" font-family=\"Times,serif\" font-size=\"14.00\">[(None, 500)]</text>\n</g>\n<!-- 139924285263344 -->\n<g id=\"node2\" class=\"node\">\n<title>139924285263344</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"18,-581.5 18,-627.5 206,-627.5 206,-581.5 18,-581.5\"/>\n<text text-anchor=\"middle\" x=\"43\" y=\"-600.8\" font-family=\"Times,serif\" font-size=\"14.00\">Dense</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"68,-581.5 68,-627.5 \"/>\n<text text-anchor=\"middle\" x=\"95.5\" y=\"-612.3\" font-family=\"Times,serif\" font-size=\"14.00\">input:</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"68,-604.5 123,-604.5 \"/>\n<text text-anchor=\"middle\" x=\"95.5\" y=\"-589.3\" font-family=\"Times,serif\" font-size=\"14.00\">output:</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"123,-581.5 123,-627.5 \"/>\n<text text-anchor=\"middle\" x=\"164.5\" y=\"-612.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 500)</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"123,-604.5 206,-604.5 \"/>\n<text text-anchor=\"middle\" x=\"164.5\" y=\"-589.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 512)</text>\n</g>\n<!-- 139924285273904&#45;&gt;139924285263344 -->\n<g id=\"edge1\" class=\"edge\">\n<title>139924285273904-&gt;139924285263344</title>\n<path fill=\"none\" stroke=\"black\" d=\"M112,-664.37C112,-656.15 112,-646.66 112,-637.73\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"115.5,-637.61 112,-627.61 108.5,-637.61 115.5,-637.61\"/>\n</g>\n<!-- 139924342547232 -->\n<g id=\"node3\" class=\"node\">\n<title>139924342547232</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"12,-498.5 12,-544.5 212,-544.5 212,-498.5 12,-498.5\"/>\n<text text-anchor=\"middle\" x=\"43\" y=\"-517.8\" font-family=\"Times,serif\" font-size=\"14.00\">Dropout</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"74,-498.5 74,-544.5 \"/>\n<text text-anchor=\"middle\" x=\"101.5\" y=\"-529.3\" font-family=\"Times,serif\" font-size=\"14.00\">input:</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"74,-521.5 129,-521.5 \"/>\n<text text-anchor=\"middle\" x=\"101.5\" y=\"-506.3\" font-family=\"Times,serif\" font-size=\"14.00\">output:</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"129,-498.5 129,-544.5 \"/>\n<text text-anchor=\"middle\" x=\"170.5\" y=\"-529.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 512)</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"129,-521.5 212,-521.5 \"/>\n<text text-anchor=\"middle\" x=\"170.5\" y=\"-506.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 512)</text>\n</g>\n<!-- 139924285263344&#45;&gt;139924342547232 -->\n<g id=\"edge2\" class=\"edge\">\n<title>139924285263344-&gt;139924342547232</title>\n<path fill=\"none\" stroke=\"black\" d=\"M112,-581.37C112,-573.15 112,-563.66 112,-554.73\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"115.5,-554.61 112,-544.61 108.5,-554.61 115.5,-554.61\"/>\n</g>\n<!-- 139924267614848 -->\n<g id=\"node4\" class=\"node\">\n<title>139924267614848</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"18,-415.5 18,-461.5 206,-461.5 206,-415.5 18,-415.5\"/>\n<text text-anchor=\"middle\" x=\"43\" y=\"-434.8\" font-family=\"Times,serif\" font-size=\"14.00\">Dense</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"68,-415.5 68,-461.5 \"/>\n<text text-anchor=\"middle\" x=\"95.5\" y=\"-446.3\" font-family=\"Times,serif\" font-size=\"14.00\">input:</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"68,-438.5 123,-438.5 \"/>\n<text text-anchor=\"middle\" x=\"95.5\" y=\"-423.3\" font-family=\"Times,serif\" font-size=\"14.00\">output:</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"123,-415.5 123,-461.5 \"/>\n<text text-anchor=\"middle\" x=\"164.5\" y=\"-446.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 512)</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"123,-438.5 206,-438.5 \"/>\n<text text-anchor=\"middle\" x=\"164.5\" y=\"-423.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 512)</text>\n</g>\n<!-- 139924342547232&#45;&gt;139924267614848 -->\n<g id=\"edge3\" class=\"edge\">\n<title>139924342547232-&gt;139924267614848</title>\n<path fill=\"none\" stroke=\"black\" d=\"M112,-498.37C112,-490.15 112,-480.66 112,-471.73\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"115.5,-471.61 112,-461.61 108.5,-471.61 115.5,-471.61\"/>\n</g>\n<!-- 139924267618640 -->\n<g id=\"node5\" class=\"node\">\n<title>139924267618640</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"12,-332.5 12,-378.5 212,-378.5 212,-332.5 12,-332.5\"/>\n<text text-anchor=\"middle\" x=\"43\" y=\"-351.8\" font-family=\"Times,serif\" font-size=\"14.00\">Dropout</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"74,-332.5 74,-378.5 \"/>\n<text text-anchor=\"middle\" x=\"101.5\" y=\"-363.3\" font-family=\"Times,serif\" font-size=\"14.00\">input:</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"74,-355.5 129,-355.5 \"/>\n<text text-anchor=\"middle\" x=\"101.5\" y=\"-340.3\" font-family=\"Times,serif\" font-size=\"14.00\">output:</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"129,-332.5 129,-378.5 \"/>\n<text text-anchor=\"middle\" x=\"170.5\" y=\"-363.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 512)</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"129,-355.5 212,-355.5 \"/>\n<text text-anchor=\"middle\" x=\"170.5\" y=\"-340.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 512)</text>\n</g>\n<!-- 139924267614848&#45;&gt;139924267618640 -->\n<g id=\"edge4\" class=\"edge\">\n<title>139924267614848-&gt;139924267618640</title>\n<path fill=\"none\" stroke=\"black\" d=\"M112,-415.37C112,-407.15 112,-397.66 112,-388.73\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"115.5,-388.61 112,-378.61 108.5,-388.61 115.5,-388.61\"/>\n</g>\n<!-- 139924267618880 -->\n<g id=\"node6\" class=\"node\">\n<title>139924267618880</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"18,-249.5 18,-295.5 206,-295.5 206,-249.5 18,-249.5\"/>\n<text text-anchor=\"middle\" x=\"43\" y=\"-268.8\" font-family=\"Times,serif\" font-size=\"14.00\">Dense</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"68,-249.5 68,-295.5 \"/>\n<text text-anchor=\"middle\" x=\"95.5\" y=\"-280.3\" font-family=\"Times,serif\" font-size=\"14.00\">input:</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"68,-272.5 123,-272.5 \"/>\n<text text-anchor=\"middle\" x=\"95.5\" y=\"-257.3\" font-family=\"Times,serif\" font-size=\"14.00\">output:</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"123,-249.5 123,-295.5 \"/>\n<text text-anchor=\"middle\" x=\"164.5\" y=\"-280.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 512)</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"123,-272.5 206,-272.5 \"/>\n<text text-anchor=\"middle\" x=\"164.5\" y=\"-257.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 512)</text>\n</g>\n<!-- 139924267618640&#45;&gt;139924267618880 -->\n<g id=\"edge5\" class=\"edge\">\n<title>139924267618640-&gt;139924267618880</title>\n<path fill=\"none\" stroke=\"black\" d=\"M112,-332.37C112,-324.15 112,-314.66 112,-305.73\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"115.5,-305.61 112,-295.61 108.5,-305.61 115.5,-305.61\"/>\n</g>\n<!-- 139924267623632 -->\n<g id=\"node7\" class=\"node\">\n<title>139924267623632</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"12,-166.5 12,-212.5 212,-212.5 212,-166.5 12,-166.5\"/>\n<text text-anchor=\"middle\" x=\"43\" y=\"-185.8\" font-family=\"Times,serif\" font-size=\"14.00\">Dropout</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"74,-166.5 74,-212.5 \"/>\n<text text-anchor=\"middle\" x=\"101.5\" y=\"-197.3\" font-family=\"Times,serif\" font-size=\"14.00\">input:</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"74,-189.5 129,-189.5 \"/>\n<text text-anchor=\"middle\" x=\"101.5\" y=\"-174.3\" font-family=\"Times,serif\" font-size=\"14.00\">output:</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"129,-166.5 129,-212.5 \"/>\n<text text-anchor=\"middle\" x=\"170.5\" y=\"-197.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 512)</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"129,-189.5 212,-189.5 \"/>\n<text text-anchor=\"middle\" x=\"170.5\" y=\"-174.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 512)</text>\n</g>\n<!-- 139924267618880&#45;&gt;139924267623632 -->\n<g id=\"edge6\" class=\"edge\">\n<title>139924267618880-&gt;139924267623632</title>\n<path fill=\"none\" stroke=\"black\" d=\"M112,-249.37C112,-241.15 112,-231.66 112,-222.73\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"115.5,-222.61 112,-212.61 108.5,-222.61 115.5,-222.61\"/>\n</g>\n<!-- 139924267626128 -->\n<g id=\"node8\" class=\"node\">\n<title>139924267626128</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"18,-83.5 18,-129.5 206,-129.5 206,-83.5 18,-83.5\"/>\n<text text-anchor=\"middle\" x=\"43\" y=\"-102.8\" font-family=\"Times,serif\" font-size=\"14.00\">Dense</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"68,-83.5 68,-129.5 \"/>\n<text text-anchor=\"middle\" x=\"95.5\" y=\"-114.3\" font-family=\"Times,serif\" font-size=\"14.00\">input:</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"68,-106.5 123,-106.5 \"/>\n<text text-anchor=\"middle\" x=\"95.5\" y=\"-91.3\" font-family=\"Times,serif\" font-size=\"14.00\">output:</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"123,-83.5 123,-129.5 \"/>\n<text text-anchor=\"middle\" x=\"164.5\" y=\"-114.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 512)</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"123,-106.5 206,-106.5 \"/>\n<text text-anchor=\"middle\" x=\"164.5\" y=\"-91.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 2)</text>\n</g>\n<!-- 139924267623632&#45;&gt;139924267626128 -->\n<g id=\"edge7\" class=\"edge\">\n<title>139924267623632-&gt;139924267626128</title>\n<path fill=\"none\" stroke=\"black\" d=\"M112,-166.37C112,-158.15 112,-148.66 112,-139.73\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"115.5,-139.61 112,-129.61 108.5,-139.61 115.5,-139.61\"/>\n</g>\n<!-- 139924267627184 -->\n<g id=\"node9\" class=\"node\">\n<title>139924267627184</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"13,-0.5 13,-46.5 211,-46.5 211,-0.5 13,-0.5\"/>\n<text text-anchor=\"middle\" x=\"50\" y=\"-19.8\" font-family=\"Times,serif\" font-size=\"14.00\">Activation</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"87,-0.5 87,-46.5 \"/>\n<text text-anchor=\"middle\" x=\"114.5\" y=\"-31.3\" font-family=\"Times,serif\" font-size=\"14.00\">input:</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"87,-23.5 142,-23.5 \"/>\n<text text-anchor=\"middle\" x=\"114.5\" y=\"-8.3\" font-family=\"Times,serif\" font-size=\"14.00\">output:</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"142,-0.5 142,-46.5 \"/>\n<text text-anchor=\"middle\" x=\"176.5\" y=\"-31.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 2)</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"142,-23.5 211,-23.5 \"/>\n<text text-anchor=\"middle\" x=\"176.5\" y=\"-8.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 2)</text>\n</g>\n<!-- 139924267626128&#45;&gt;139924267627184 -->\n<g id=\"edge8\" class=\"edge\">\n<title>139924267626128-&gt;139924267627184</title>\n<path fill=\"none\" stroke=\"black\" d=\"M112,-83.37C112,-75.15 112,-65.66 112,-56.73\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"115.5,-56.61 112,-46.61 108.5,-56.61 115.5,-56.61\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "from IPython.display import SVG\n",
        "from keras.utils import model_to_dot\n",
        "\n",
        "SVG(model_to_dot(w2v_dnn, show_shapes=True, show_layer_names=False,\n",
        "                 rankdir='TB').create(prog='dot', format='svg'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j89trS0t20NP"
      },
      "source": [
        "### Model Training, Prediction and Performance Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "MIXBDB7O20NP",
        "outputId": "45682744-b104-4f21-b23a-39dc3a24f94c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "45/45 [==============================] - 2s 27ms/step - loss: 0.5039 - accuracy: 0.7584 - val_loss: 0.4902 - val_accuracy: 0.7520\n",
            "Epoch 2/5\n",
            "45/45 [==============================] - 1s 22ms/step - loss: 0.4618 - accuracy: 0.7820 - val_loss: 0.4705 - val_accuracy: 0.7840\n",
            "Epoch 3/5\n",
            "45/45 [==============================] - 1s 21ms/step - loss: 0.4454 - accuracy: 0.7931 - val_loss: 0.4629 - val_accuracy: 0.7620\n",
            "Epoch 4/5\n",
            "45/45 [==============================] - 1s 23ms/step - loss: 0.4431 - accuracy: 0.7962 - val_loss: 0.4515 - val_accuracy: 0.7880\n",
            "Epoch 5/5\n",
            "45/45 [==============================] - 1s 32ms/step - loss: 0.4328 - accuracy: 0.8038 - val_loss: 0.4459 - val_accuracy: 0.7800\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f42a82431f0>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "batch_size = 100\n",
        "w2v_dnn.fit(avg_wv_train_features, y_train, epochs=5, batch_size=batch_size,\n",
        "            shuffle=True, validation_split=0.1, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "iyuMHlgL20NP",
        "outputId": "45f4b29e-a874-457e-cfd1-696c62d5521c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 0s 7ms/step\n"
          ]
        }
      ],
      "source": [
        "y_pred = w2v_dnn.predict(avg_wv_test_features)\n",
        "y_classes = np.argmax(y_pred, axis=1)\n",
        "predictions = le.inverse_transform(y_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "azX1N5TC20NP",
        "outputId": "28d61dfc-ba57-4f0e-a882-4b18cfd01412",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Performance metrics:\n",
            "------------------------------\n",
            "Accuracy: 0.802\n",
            "Precision: 0.8022\n",
            "Recall: 0.802\n",
            "F1 Score: 0.802\n",
            "\n",
            "Model Classification report:\n",
            "------------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    positive       0.79      0.81      0.80       981\n",
            "    negative       0.81      0.79      0.80      1019\n",
            "\n",
            "    accuracy                           0.80      2000\n",
            "   macro avg       0.80      0.80      0.80      2000\n",
            "weighted avg       0.80      0.80      0.80      2000\n",
            "\n",
            "\n",
            "Prediction Confusion Matrix:\n",
            "------------------------------\n",
            "                 Predicted:         \n",
            "                   positive negative\n",
            "Actual: positive        794      187\n",
            "        negative        209      810\n"
          ]
        }
      ],
      "source": [
        "meu.display_model_performance_metrics(true_labels=test_sentiments, predicted_labels=predictions,\n",
        "                                      classes=['positive', 'negative'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "collapsed": true,
        "id": "WjdRED6e20NP"
      },
      "outputs": [],
      "source": [
        "glove_dnn = construct_deepnn_architecture(num_input_features=96)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "wchl8iCz20NP",
        "outputId": "89393799-77d2-4a37-f1d7-f06aecc1da21",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "45/45 [==============================] - 2s 23ms/step - loss: 0.6719 - accuracy: 0.5840 - val_loss: 0.6545 - val_accuracy: 0.6080\n",
            "Epoch 2/5\n",
            "45/45 [==============================] - 1s 19ms/step - loss: 0.6537 - accuracy: 0.6158 - val_loss: 0.6517 - val_accuracy: 0.6080\n",
            "Epoch 3/5\n",
            "45/45 [==============================] - 1s 18ms/step - loss: 0.6438 - accuracy: 0.6220 - val_loss: 0.6348 - val_accuracy: 0.6340\n",
            "Epoch 4/5\n",
            "45/45 [==============================] - 1s 18ms/step - loss: 0.6329 - accuracy: 0.6462 - val_loss: 0.6360 - val_accuracy: 0.6320\n",
            "Epoch 5/5\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.6216 - accuracy: 0.6604 - val_loss: 0.6299 - val_accuracy: 0.6500\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f4299de0c10>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "batch_size = 100\n",
        "glove_dnn.fit(train_glove_features, y_train, epochs=5, batch_size=batch_size,\n",
        "              shuffle=True, validation_split=0.1, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "sS1n0U9L20NP",
        "outputId": "ed1db354-459f-4e8c-cdf4-421a4d33ac05",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 0s 5ms/step\n"
          ]
        }
      ],
      "source": [
        "y_pred = glove_dnn.predict(test_glove_features)\n",
        "y_classes = np.argmax(y_pred, axis=1)\n",
        "predictions = le.inverse_transform(y_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "ScGhZ_v120NQ",
        "outputId": "4903929c-0801-4def-dce5-82a6d563a2d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Performance metrics:\n",
            "------------------------------\n",
            "Accuracy: 0.65\n",
            "Precision: 0.6562\n",
            "Recall: 0.65\n",
            "F1 Score: 0.6478\n",
            "\n",
            "Model Classification report:\n",
            "------------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    positive       0.62      0.73      0.67       981\n",
            "    negative       0.69      0.57      0.62      1019\n",
            "\n",
            "    accuracy                           0.65      2000\n",
            "   macro avg       0.66      0.65      0.65      2000\n",
            "weighted avg       0.66      0.65      0.65      2000\n",
            "\n",
            "\n",
            "Prediction Confusion Matrix:\n",
            "------------------------------\n",
            "                 Predicted:         \n",
            "                   positive negative\n",
            "Actual: positive        721      260\n",
            "        negative        440      579\n"
          ]
        }
      ],
      "source": [
        "meu.display_model_performance_metrics(true_labels=test_sentiments, predicted_labels=predictions,\n",
        "                                      classes=['positive', 'negative'])"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}